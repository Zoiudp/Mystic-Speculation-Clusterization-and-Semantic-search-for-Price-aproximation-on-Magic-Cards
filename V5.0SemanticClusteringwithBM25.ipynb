{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\drodm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\drodm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 495\u001b[0m, in \u001b[0;36mmain.<locals>.on_button_click\u001b[1;34m()\u001b[0m\n\u001b[0;32m    491\u001b[0m     loyalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# Force pass values to run_analysis\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m \u001b[43mrun_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcard_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmana_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcard_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoughness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_rarity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloyalty\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 412\u001b[0m, in \u001b[0;36mrun_analysis\u001b[1;34m(card_type, mana_cost, card_text, power, toughness, rarity, loyalty)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_analysis\u001b[39m(card_type, mana_cost, card_text, power, toughness, rarity, loyalty):\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# Print for debugging to ensure values are captured\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;66;03m#print(f\"Card Type: {card_type}, Mana Cost: {mana_cost}, Text: {card_text}, Power: {power}, Toughness: {toughness}, Rarity: {rarity}, Loyalty: {loyalty}\")\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m     \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCard_Type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcard_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTexto_a_procurar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcard_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mToughness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoughness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCMC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmana_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRarity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrarity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLoyalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloyalty\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 373\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(Card_Type, Texto_a_procurar, Power, Toughness, CMC, Rarity, Loyalty)\u001b[0m\n\u001b[0;32m    371\u001b[0m filtered_predict \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mpredict_and_filter(clustering_model,busca)\n\u001b[0;32m    372\u001b[0m features, target \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mscale_data(filtered_predict[columns_by_type[Card_Type]]\u001b[38;5;241m.\u001b[39mdropna(), filtered_predict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrice1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 373\u001b[0m X_train_Minimum , X_test_Minimum, y_train_Minimum, y_test_Minimum \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m features, target \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mscale_data(filtered_predict[columns_by_type[Card_Type]]\u001b[38;5;241m.\u001b[39mdropna(), filtered_predict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrice2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    375\u001b[0m X_train_Medium  , X_test_Medium, y_train_Medium, y_test_Medium \u001b[38;5;241m=\u001b[39m train_test_split(features, target, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2785\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2782\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2784\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2785\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2415\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2412\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2416\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2419\u001b[0m     )\n\u001b[0;32m   2421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=1, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 495\u001b[0m, in \u001b[0;36mmain.<locals>.on_button_click\u001b[1;34m()\u001b[0m\n\u001b[0;32m    491\u001b[0m     loyalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# Force pass values to run_analysis\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m \u001b[43mrun_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcard_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmana_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcard_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoughness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_rarity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloyalty\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 412\u001b[0m, in \u001b[0;36mrun_analysis\u001b[1;34m(card_type, mana_cost, card_text, power, toughness, rarity, loyalty)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_analysis\u001b[39m(card_type, mana_cost, card_text, power, toughness, rarity, loyalty):\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# Print for debugging to ensure values are captured\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;66;03m#print(f\"Card Type: {card_type}, Mana Cost: {mana_cost}, Text: {card_text}, Power: {power}, Toughness: {toughness}, Rarity: {rarity}, Loyalty: {loyalty}\")\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m     \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCard_Type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcard_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTexto_a_procurar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcard_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mToughness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoughness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCMC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmana_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRarity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrarity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLoyalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloyalty\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 373\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(Card_Type, Texto_a_procurar, Power, Toughness, CMC, Rarity, Loyalty)\u001b[0m\n\u001b[0;32m    371\u001b[0m filtered_predict \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mpredict_and_filter(clustering_model,busca)\n\u001b[0;32m    372\u001b[0m features, target \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mscale_data(filtered_predict[columns_by_type[Card_Type]]\u001b[38;5;241m.\u001b[39mdropna(), filtered_predict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrice1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 373\u001b[0m X_train_Minimum , X_test_Minimum, y_train_Minimum, y_test_Minimum \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m features, target \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mscale_data(filtered_predict[columns_by_type[Card_Type]]\u001b[38;5;241m.\u001b[39mdropna(), filtered_predict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrice2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    375\u001b[0m X_train_Medium  , X_test_Medium, y_train_Medium, y_test_Medium \u001b[38;5;241m=\u001b[39m train_test_split(features, target, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2785\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2782\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2784\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2785\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2415\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2412\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2416\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2419\u001b[0m     )\n\u001b[0;32m   2421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=1, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 495\u001b[0m, in \u001b[0;36mmain.<locals>.on_button_click\u001b[1;34m()\u001b[0m\n\u001b[0;32m    491\u001b[0m     loyalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# Force pass values to run_analysis\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m \u001b[43mrun_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcard_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmana_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcard_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoughness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_rarity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloyalty\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 412\u001b[0m, in \u001b[0;36mrun_analysis\u001b[1;34m(card_type, mana_cost, card_text, power, toughness, rarity, loyalty)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_analysis\u001b[39m(card_type, mana_cost, card_text, power, toughness, rarity, loyalty):\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# Print for debugging to ensure values are captured\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;66;03m#print(f\"Card Type: {card_type}, Mana Cost: {mana_cost}, Text: {card_text}, Power: {power}, Toughness: {toughness}, Rarity: {rarity}, Loyalty: {loyalty}\")\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m     \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCard_Type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcard_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTexto_a_procurar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcard_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mToughness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoughness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCMC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmana_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRarity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrarity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLoyalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloyalty\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 373\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(Card_Type, Texto_a_procurar, Power, Toughness, CMC, Rarity, Loyalty)\u001b[0m\n\u001b[0;32m    371\u001b[0m filtered_predict \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mpredict_and_filter(clustering_model,busca)\n\u001b[0;32m    372\u001b[0m features, target \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mscale_data(filtered_predict[columns_by_type[Card_Type]]\u001b[38;5;241m.\u001b[39mdropna(), filtered_predict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrice1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 373\u001b[0m X_train_Minimum , X_test_Minimum, y_train_Minimum, y_test_Minimum \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m features, target \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mscale_data(filtered_predict[columns_by_type[Card_Type]]\u001b[38;5;241m.\u001b[39mdropna(), filtered_predict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrice2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    375\u001b[0m X_train_Medium  , X_test_Medium, y_train_Medium, y_test_Medium \u001b[38;5;241m=\u001b[39m train_test_split(features, target, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2785\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2782\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2784\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2785\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2415\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2412\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2416\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2419\u001b[0m     )\n\u001b[0;32m   2421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=1, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 495\u001b[0m, in \u001b[0;36mmain.<locals>.on_button_click\u001b[1;34m()\u001b[0m\n\u001b[0;32m    491\u001b[0m     loyalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# Force pass values to run_analysis\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m \u001b[43mrun_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcard_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmana_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcard_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoughness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_rarity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloyalty\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 412\u001b[0m, in \u001b[0;36mrun_analysis\u001b[1;34m(card_type, mana_cost, card_text, power, toughness, rarity, loyalty)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_analysis\u001b[39m(card_type, mana_cost, card_text, power, toughness, rarity, loyalty):\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# Print for debugging to ensure values are captured\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;66;03m#print(f\"Card Type: {card_type}, Mana Cost: {mana_cost}, Text: {card_text}, Power: {power}, Toughness: {toughness}, Rarity: {rarity}, Loyalty: {loyalty}\")\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m     \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCard_Type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcard_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTexto_a_procurar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcard_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mToughness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoughness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCMC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmana_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRarity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrarity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLoyalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloyalty\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 373\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(Card_Type, Texto_a_procurar, Power, Toughness, CMC, Rarity, Loyalty)\u001b[0m\n\u001b[0;32m    371\u001b[0m filtered_predict \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mpredict_and_filter(clustering_model,busca)\n\u001b[0;32m    372\u001b[0m features, target \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mscale_data(filtered_predict[columns_by_type[Card_Type]]\u001b[38;5;241m.\u001b[39mdropna(), filtered_predict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrice1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 373\u001b[0m X_train_Minimum , X_test_Minimum, y_train_Minimum, y_test_Minimum \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m features, target \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mscale_data(filtered_predict[columns_by_type[Card_Type]]\u001b[38;5;241m.\u001b[39mdropna(), filtered_predict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrice2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    375\u001b[0m X_train_Medium  , X_test_Medium, y_train_Medium, y_test_Medium \u001b[38;5;241m=\u001b[39m train_test_split(features, target, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2785\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2782\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2784\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2785\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2415\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2412\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2416\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2419\u001b[0m     )\n\u001b[0;32m   2421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=1, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carta mais semelhante:  Arlinn, Voice of the Pack Texto da carta:  Each creature you control that's a Wolf or a Werewolf enters with an additional +1/+1 counter on it.\n",
      "−2: Create a 2/2 green Wolf creature token.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 495\u001b[0m, in \u001b[0;36mmain.<locals>.on_button_click\u001b[1;34m()\u001b[0m\n\u001b[0;32m    491\u001b[0m     loyalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# Force pass values to run_analysis\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m \u001b[43mrun_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcard_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmana_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcard_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoughness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_rarity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloyalty\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 412\u001b[0m, in \u001b[0;36mrun_analysis\u001b[1;34m(card_type, mana_cost, card_text, power, toughness, rarity, loyalty)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_analysis\u001b[39m(card_type, mana_cost, card_text, power, toughness, rarity, loyalty):\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# Print for debugging to ensure values are captured\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;66;03m#print(f\"Card Type: {card_type}, Mana Cost: {mana_cost}, Text: {card_text}, Power: {power}, Toughness: {toughness}, Rarity: {rarity}, Loyalty: {loyalty}\")\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m     \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCard_Type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcard_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTexto_a_procurar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcard_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mToughness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoughness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCMC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmana_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRarity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrarity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLoyalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloyalty\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 380\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(Card_Type, Texto_a_procurar, Power, Toughness, CMC, Rarity, Loyalty)\u001b[0m\n\u001b[0;32m    377\u001b[0m X_train_Maximum, X_test_Maximum, y_train_Maximum, y_test_Maximum \u001b[38;5;241m=\u001b[39m train_test_split(features, target, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;66;03m# Continue with visualization and analysis\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualize_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCard_Type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m analyzer\u001b[38;5;241m.\u001b[39mbayesian_analysis(filtered_predict)\n\u001b[0;32m    382\u001b[0m analyzer\u001b[38;5;241m.\u001b[39mtrain_random_forest(X_train_Minimum, y_train_Minimum)\n",
      "Cell \u001b[1;32mIn[24], line 231\u001b[0m, in \u001b[0;36mCardAnalyzer.visualize_3d\u001b[1;34m(self, filtered_predict, Card_Type)\u001b[0m\n\u001b[0;32m    228\u001b[0m features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m    230\u001b[0m umap_3d \u001b[38;5;241m=\u001b[39m UMAP(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m--> 231\u001b[0m proj_3d \u001b[38;5;241m=\u001b[39m \u001b[43mumap_3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m y \u001b[38;5;241m=\u001b[39m filtered_predict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Mana Cost\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m Card_Type \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLand\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m filtered_predict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRarity Category\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    233\u001b[0m fig_3d \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mscatter_3d(\n\u001b[0;32m    234\u001b[0m     proj_3d,\n\u001b[0;32m    235\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    248\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCartas Semelhantes\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    249\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\umap\\umap_.py:2891\u001b[0m, in \u001b[0;36mUMAP.fit_transform\u001b[1;34m(self, X, y, force_all_finite)\u001b[0m\n\u001b[0;32m   2855\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   2856\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed\u001b[39;00m\n\u001b[0;32m   2857\u001b[0m \u001b[38;5;124;03m    output.\u001b[39;00m\n\u001b[0;32m   2858\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2889\u001b[0m \u001b[38;5;124;03m        Local radii of data points in the embedding (log-transformed).\u001b[39;00m\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2891\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2893\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dens:\n",
      "File \u001b[1;32mc:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\umap\\umap_.py:2784\u001b[0m, in \u001b[0;36mUMAP.fit\u001b[1;34m(self, X, y, force_all_finite)\u001b[0m\n\u001b[0;32m   2780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2781\u001b[0m     epochs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2782\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epochs_list \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epochs_list \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epochs\n\u001b[0;32m   2783\u001b[0m     )\n\u001b[1;32m-> 2784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_, aux_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_embed_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2785\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2786\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2787\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2788\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# JH why raw data?\u001b[39;49;00m\n\u001b[0;32m   2789\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epochs_list \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2792\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_list\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m aux_data:\n",
      "File \u001b[1;32mc:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\umap\\umap_.py:2830\u001b[0m, in \u001b[0;36mUMAP._fit_embed_data\u001b[1;34m(self, X, n_epochs, init, random_state)\u001b[0m\n\u001b[0;32m   2826\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit_embed_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, n_epochs, init, random_state):\n\u001b[0;32m   2827\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A method wrapper for simplicial_set_embedding that can be\u001b[39;00m\n\u001b[0;32m   2828\u001b[0m \u001b[38;5;124;03m    replaced by subclasses.\u001b[39;00m\n\u001b[0;32m   2829\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2830\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msimplicial_set_embedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2833\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initial_alpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_a\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2836\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_b\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2837\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepulsion_strength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2838\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnegative_sample_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2840\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2842\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_distance_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2843\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metric_kwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2844\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdensmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2845\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_densmap_kwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2846\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_dens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2847\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_distance_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_metric_kwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2849\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_metric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meuclidean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ml2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2850\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_kwds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtqdm_kwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2853\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\umap\\umap_.py:1087\u001b[0m, in \u001b[0;36msimplicial_set_embedding\u001b[1;34m(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, densmap, densmap_kwds, output_dens, output_metric, output_metric_kwds, euclidean_output, parallel, verbose, tqdm_kwds)\u001b[0m\n\u001b[0;32m   1084\u001b[0m n_epochs_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n_epochs) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n_epochs, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m n_epochs\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_epochs_max \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m-> 1087\u001b[0m     graph\u001b[38;5;241m.\u001b[39mdata[graph\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m<\u001b[39m (\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(n_epochs_max))] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1089\u001b[0m     graph\u001b[38;5;241m.\u001b[39mdata[graph\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m<\u001b[39m (graph\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(default_epochs))] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:41\u001b[0m, in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     40\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_maximum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from umap import UMAP\n",
    "import plotly.express as px\n",
    "import dearpygui.dearpygui as dpg\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy import stats\n",
    "import nltk\n",
    "from rank_bm25 import BM25Okapi\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "# Sample card types for selection\n",
    "card_types = [\"Creature\", \"Sorcery\", \"Instant\", \"Enchantment\", \"Planeswalker\", \"Land\", \"Artifact\", \"Artifact Creature\"]\n",
    "\n",
    "columns_by_type = {\n",
    "    'Creature': ['Total Mana Cost', 'Power', 'Toughness', 'Rarity Category','BM25 Score'],\n",
    "    'Sorcery': ['Total Mana Cost', 'Rarity Category','BM25 Score'],\n",
    "    'Instant': ['Total Mana Cost', 'Rarity Category','BM25 Score'],\n",
    "    'Enchantment': ['Total Mana Cost', 'Rarity Category','BM25 Score'],\n",
    "    'Planeswalker': ['Total Mana Cost', 'Rarity Category', 'loyalty','BM25 Score'],\n",
    "    'Land': ['Rarity Category','BM25 Score'],\n",
    "    'Artifact': ['Total Mana Cost', 'Rarity Category','BM25 Score'],\n",
    "    'Artifact Creature': ['Total Mana Cost', 'Power', 'Toughness', 'Rarity Category','BM25 Score']\n",
    "}\n",
    "# Sample rarity mapping\n",
    "rarity_mapping = {'common': 0, 'uncommon': 1, 'rare': 2, 'mythic': 3}\n",
    "\n",
    "class DataPreprocessing:\n",
    "    def __init__(self):\n",
    "        return None\n",
    "\n",
    "    def merging_data(self, data1, data2):\n",
    "        self.data1 = data1\n",
    "        self.data2 = data2\n",
    "        return data1.merge(data2[['Name', 'rarity', 'loyalty']], on='Name', how='left')\n",
    "    \n",
    "    def preprocess(self, data: pd.DataFrame, Card_Type: str):\n",
    "        self.data = data\n",
    "        data.dropna()\n",
    "        data.drop_duplicates(subset='Name', inplace=True)\n",
    "        data.drop(columns=[\"Unnamed: 0\",\"Unnamed: 0.1\"], inplace=True)\n",
    "        data.drop(columns=[\"Expansion Name\",\"Expansion Code\"], inplace=True)\n",
    "        data[['Price1', 'Price2', 'Price3']] = data[['Price1', 'Price2', 'Price3']].replace('[R$]', '', regex=True).replace(',','.',regex=True).apply(pd.to_numeric, errors='coerce')\n",
    "        # Convert the 'rarity' column to numeric categories\n",
    "        rarity_mapping = {'common': 0, 'uncommon': 1, 'rare': 2, 'mythic': 3}\n",
    "        data['Rarity Category'] = data['rarity'].map(rarity_mapping).fillna(-1).astype(int)\n",
    "        creatures = data[data['Card Type'].str.contains('Creature', na=False)].drop(columns=[\"Release Date\",'Color', 'Mana Cost','loyalty'], inplace=False)\n",
    "        creatures[['Total Mana Cost', 'Power', 'Toughness']] = creatures[['Total Mana Cost', 'Power', 'Toughness']].apply(pd.to_numeric, errors='coerce')\n",
    "        creatures = creatures[(creatures['Power'] != -1) & (creatures['Toughness'] != -1)].dropna(subset=['Power', 'Toughness', 'Oracle Text'])\n",
    "        sorcery = data[data['Card Type'].str.contains('Sorcery', na=False)].drop(columns=[\"Release Date\", 'Color', 'Mana Cost','Power','Toughness','loyalty'], inplace=False)\n",
    "        instant = data[data['Card Type'].str.contains('Instant', na=False)].drop(columns=[\"Release Date\", 'Color', 'Mana Cost','Power','Toughness','loyalty'], inplace=False)\n",
    "        enchantment = data[data['Card Type'].str.contains('Enchantment', na=False)].drop(columns=[\"Release Date\", 'Color', 'Mana Cost','Power','Toughness','loyalty'], inplace=False)\n",
    "        planeswalker = data[data['Card Type'].str.contains('Planeswalker', na=False)].drop(columns=[\"Release Date\", 'Color', 'Mana Cost','Power','Toughness'], inplace=False)\n",
    "        terr = data[data['Card Type'].str.contains('Land', na=False)].drop(columns=[\"Release Date\", 'Color','Total Mana Cost', 'Mana Cost','Power','Toughness','loyalty'], inplace=False)\n",
    "        art = data[data['Card Type'].str.contains('Artifact', na=False)].drop(columns=[\"Release Date\", 'Color', 'Mana Cost','loyalty'], inplace=False)\n",
    "        art_creatures = art[art['Card Type'].str.contains('Creature', na=False)]\n",
    "        art_creatures = art_creatures[(art_creatures['Power'] != -1) & (art_creatures['Toughness'] != -1)].dropna(subset=['Power', 'Toughness', 'Oracle Text'])\n",
    "        art_creatures[['Total Mana Cost', 'Power', 'Toughness']] = art_creatures[['Total Mana Cost', 'Power', 'Toughness']].apply(pd.to_numeric, errors='coerce')\n",
    "        art = art[~art['Card Type'].str.contains('Creature', na=False)].drop(columns=['Power','Toughness'], inplace=False)\n",
    "        art = art[~art['Card Type'].str.contains('Land', na=False)]\n",
    "\n",
    "        if(Card_Type == 'Creature'):\n",
    "            return creatures\n",
    "        elif(Card_Type == 'Sorcery'):\n",
    "            return sorcery\n",
    "        elif(Card_Type == 'Instant'):\n",
    "            return instant\n",
    "        elif(Card_Type == 'Enchantment'):\n",
    "            return enchantment\n",
    "        elif(Card_Type == 'Planeswalker'):\n",
    "            return planeswalker\n",
    "        elif(Card_Type == 'Land'):\n",
    "            return terr\n",
    "        elif(Card_Type == 'Artifact'):\n",
    "            return art\n",
    "        elif(Card_Type == 'Artifact Creature'):\n",
    "            return art_creatures\n",
    "        else:\n",
    "            return pd.DataFrame()  # Return an empty DataFrame for invalid Card Type\n",
    "\n",
    "class CardAnalyzer:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.clustering_model = None\n",
    "        self.pipe = None\n",
    "        self.scale = MinMaxScaler()\n",
    "        self.rfr = XGBRegressor(n_estimators=100)\n",
    "        self.knn_regressor = SVR(kernel='rbf')\n",
    "\n",
    "    def clean_data(self, Card_Type: str):\n",
    "\n",
    "        \"\"\"Clean and filter the dataframe for creatures.\"\"\"\n",
    "        if(Card_Type == \"Creature\" or Card_Type == \"Artifact Creature\"):\n",
    "            self.df = self.df[(self.df['Power'] != -1) & (self.df['Toughness'] != -1)]\n",
    "            self.df = self.df.dropna(subset=['Power', 'Toughness', 'Oracle Text'])\n",
    "        elif(Card_Type == \"Planeswalker\"):\n",
    "            self.df = self.df.dropna(subset=['loyalty'])\n",
    "            self.df = self.df[self.df['loyalty'] != 'X']\n",
    "            self.df = self.df[self.df['Total Mana Cost'] != 'X']\n",
    "        elif(Card_Type == \"Sorcery\" or Card_Type == \"Instant\" or Card_Type == \"Enchantment\"):\n",
    "            self.df = self.df.dropna(subset=['Oracle Text'])\n",
    "            self.df = self.df.dropna(subset=['Price1','Price2','Price3'])\n",
    "        elif(Card_Type == \"Land\"):\n",
    "            self.df = self.df.dropna(subset=['Price1','Price2','Price3'])\n",
    "        elif(Card_Type == \"Artifact\"):\n",
    "            self.df = self.df.dropna(subset=['Oracle Text'])\n",
    "            self.df = self.df.dropna(subset=['Price1','Price2','Price3'])\n",
    "        else:\n",
    "            print(\"Tipo de carta não suportado\")\n",
    "            return None\n",
    "\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Tokenize and preprocess the text for Jaccard similarity.\"\"\"\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        tokens = [token for token in tokens if token.isalnum() and token not in self.stop_words]\n",
    "        return tokens\n",
    "    \n",
    "    def compute_BM25_similarity(self, query):\n",
    "        \"\"\"Compute Jaccard similarity between a query and Oracle Text in the dataframe.\"\"\"\n",
    "        tokenized_query = self.preprocess_text(query)\n",
    "        self.df['Tokenized Oracle Text'] = self.df['Oracle Text'].dropna().apply(self.preprocess_text)\n",
    "        self.df['BM25 Score'] = 0\n",
    "        self.df.loc[self.df['Oracle Text'].notna(), 'BM25 Score'] = self.BM25_similarity(tokenized_query, self.df['Tokenized Oracle Text'])\n",
    "        return self.df['BM25 Score']\n",
    "        \n",
    "    @staticmethod\n",
    "    def BM25_similarity(query_set, doc_set):\n",
    "        \"\"\"Compute BM25 similarity between two sets of tokens.\"\"\"\n",
    "        bm25 = BM25Okapi(doc_set)\n",
    "        # Obtenção dos scores de relevância dos documentos\n",
    "        scores = bm25.get_scores(query_set)\n",
    "        return scores\n",
    "\n",
    "\n",
    "    def perform_clustering(self):\n",
    "        \"\"\"Cluster the dataset based on BM25 Scores.\"\"\"\n",
    "        self.clustering_model = KMeans(n_clusters=len(self.df['BM25 Score'].unique()), random_state=42)\n",
    "        self.clustering_model.fit(self.df[['BM25 Score']])\n",
    "        self.df[\"predicted_cluster\"] = self.clustering_model.labels_\n",
    "        return self.df, self.clustering_model\n",
    "\n",
    "    def train_pipe(self, feature, target):\n",
    "        \"\"\"Train the preprocessing pipeline and clustering model.\"\"\"\n",
    "        # Encode target labels\n",
    "        label_encoder = LabelEncoder()\n",
    "        true_labels = label_encoder.fit_transform(target)\n",
    "        n_clusters = len(label_encoder.classes_)\n",
    "        #print(f\"Number of clusters: {n_clusters}\")\n",
    "\n",
    "        # Define preprocessing and clustering pipelines\n",
    "        preprocessor = Pipeline(\n",
    "            [\n",
    "                (\"scaler\", MinMaxScaler()),\n",
    "            ]\n",
    "        )\n",
    "        clusterer = Pipeline(\n",
    "            [\n",
    "                (\n",
    "                    \"kmeans\",\n",
    "                    KMeans(\n",
    "                        n_clusters=n_clusters,\n",
    "                        init=\"k-means++\",\n",
    "                        n_init=100,\n",
    "                        max_iter=10000,\n",
    "                        random_state=42,\n",
    "                    )\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        self.pipe = Pipeline([(\"preprocessor\", preprocessor), (\"clusterer\", clusterer)])\n",
    "        self.pipe.fit(feature)\n",
    "\n",
    "        # Transform data and obtain clustering results\n",
    "        preprocessed_data = self.pipe.named_steps['preprocessor'].transform(feature)\n",
    "        predicted_labels = self.pipe.named_steps['clusterer'].named_steps['kmeans'].labels_\n",
    "\n",
    "        # Evaluate clustering performance\n",
    "        silhouette = silhouette_score(preprocessed_data, predicted_labels)\n",
    "        ari = adjusted_rand_score(true_labels, predicted_labels)\n",
    "        #print(f\"Silhouette Score: {silhouette}\")\n",
    "        #print(f\"Adjusted Rand Index: {ari}\")\n",
    "\n",
    "        # Assign clusters to the dataframe\n",
    "        self.df[\"predicted_cluster\"] = predicted_labels\n",
    "\n",
    "        # Store the clustering model\n",
    "        self.clustering_model = self.pipe.named_steps['clusterer'].named_steps['kmeans']\n",
    "\n",
    "        return self.df, self.clustering_model\n",
    "\n",
    "    def predict_and_filter(self, clustering_model,busca):\n",
    "        \"\"\"Predict the cluster for a test text and filter the dataset accordingly.\"\"\"\n",
    "        test_text_jaccard_score = 1.0  # Assuming a given score\n",
    "        assigned_cluster = clustering_model.predict([[test_text_jaccard_score]])[0]\n",
    "        busca = np.append(busca,assigned_cluster)\n",
    "        \n",
    "        if self.pipe is None:\n",
    "            raise ValueError(\"Pipeline 'pipe' is not initialized.\")\n",
    "        \n",
    "        predicted = self.pipe.predict(busca.reshape(1, -1))\n",
    "        filtered_predict = self.df.loc[self.df['predicted_cluster'] == predicted.item()]\n",
    "        return filtered_predict\n",
    "\n",
    "    def visualize_3d(self, filtered_predict, Card_Type: str):\n",
    "\n",
    "        print('Carta mais semelhante: ',\n",
    "              filtered_predict.iloc[filtered_predict['BM25 Score'].argmax()]['Name'],\n",
    "              'Texto da carta: ',\n",
    "              filtered_predict.iloc[filtered_predict['BM25 Score'].argmax()]['Oracle Text'])\n",
    "        \"\"\"Visualize filtered predictions in a 3D scatter plot.\"\"\"\n",
    "        features = filtered_predict.drop(columns=['Oracle Text', 'Name', 'Card Type', 'Rarity Category', 'rarity', 'Tokenized Oracle Text'])\n",
    "        features = features.dropna()\n",
    "\n",
    "        umap_3d = UMAP(n_components=3, init=\"random\", random_state=42)\n",
    "        try:\n",
    "            proj_3d = umap_3d.fit_transform(features)\n",
    "        except:\n",
    "            print('Poucas amostras para treino')\n",
    "            return None\n",
    "        y = filtered_predict[\"Total Mana Cost\"] if Card_Type != \"Land\" else filtered_predict[\"Rarity Category\"]\n",
    "        fig_3d = px.scatter_3d(\n",
    "            proj_3d,\n",
    "            y=y,\n",
    "            x=filtered_predict[\"BM25 Score\"],\n",
    "            z=filtered_predict[\"Price1\"],\n",
    "            color=filtered_predict[\"BM25 Score\"],\n",
    "            labels={\n",
    "                \"BM25 Score\": \"Jaccard\",\n",
    "                \"Total Mana Cost\": \"CMC\",\n",
    "                \"Price1\": \"Menor Preço\",\n",
    "                \"color\": \"BM25 Score\"\n",
    "            },\n",
    "            hover_data={\n",
    "                'Name': filtered_predict['Name']\n",
    "            },\n",
    "            title=\"Cartas Semelhantes\",\n",
    "        )\n",
    "        fig_3d.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title='Jaccard',\n",
    "            yaxis_title='CMC',\n",
    "            zaxis_title='Menor Preço'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig_3d.update_traces(marker=dict(size=5))\n",
    "        fig_3d.show()\n",
    "\n",
    "    def bayesian_analysis(self, filtered_predict):\n",
    "        \"\"\"Perform Bayesian analysis on the filtered data.\"\"\"\n",
    "        value_list = filtered_predict[[\"Price1\"]]\n",
    "        print('Média de Preço Mínimo para a carta: ',stats.bayes_mvs(value_list, 0.908)[0][0])\n",
    "        value_list = filtered_predict[[\"Price2\"]]\n",
    "        print('Média de Preço Médio para a carta: ',stats.bayes_mvs(value_list, 0.908)[0][0])\n",
    "        value_list = filtered_predict[[\"Price3\"]]\n",
    "        print('Média de Preço Máximo para a carta: ',stats.bayes_mvs(value_list, 0.908)[0][0])\n",
    "        \n",
    "\n",
    "    def scale_data(self, features, target):\n",
    "        \"\"\"Scale the data using RobustScaler.\"\"\"\n",
    "        self.scale = MinMaxScaler()\n",
    "\n",
    "        return self.scale.fit_transform(features), self.scale.fit_transform(target.values.reshape(-1, 1))\n",
    "\n",
    "    def train_random_forest(self, X_train, y_train):\n",
    "        \"\"\"Train a Random Forest Regressor.\"\"\"\n",
    "        self.rfr.fit(X_train, y_train)\n",
    "\n",
    "    def train_knn(self, X_train, y_train):\n",
    "        \"\"\"Train a K-Nearest Neighbors Regressor.\"\"\"\n",
    "        try:\n",
    "            self.knn_regressor.fit(X_train, y_train)\n",
    "        except:\n",
    "            print('Poucas amostras para treino')\n",
    "\n",
    "    def evaluate_model(self, X_test, y_test):\n",
    "        \"\"\"Evaluate Random Forest and KNN models on test data.\"\"\"\n",
    "        no_knn = False\n",
    "        y_pred_rfr = self.rfr.predict(X_test)\n",
    "        try:\n",
    "            y_pred_knn = self.knn_regressor.predict(X_test)\n",
    "        except:\n",
    "            print('Poucas amostras para teste')\n",
    "            no_knn = True\n",
    "        \n",
    "        if(no_knn):\n",
    "            mse_knn = 0\n",
    "        else:\n",
    "            mse_knn = mean_absolute_error(y_test, y_pred_knn)\n",
    "            \n",
    "        mse_rfr = mean_absolute_error(y_test, y_pred_rfr)\n",
    "        \n",
    "        return mse_rfr, mse_knn, no_knn\n",
    "\n",
    "    def predict_value(self, busca, no_knn):\n",
    "        \"\"\"Predict values using both models.\"\"\"\n",
    "        test_predict_rfr = self.scale.inverse_transform(self.rfr.predict(busca.reshape(1, -1)).reshape(-1, 1))\n",
    "        if(no_knn):\n",
    "            test_predict_knn = 0\n",
    "        else:\n",
    "            test_predict_knn = self.scale.inverse_transform(self.knn_regressor.predict(busca.reshape(1, -1)).reshape(-1, 1))\n",
    "        \n",
    "        return test_predict_rfr, test_predict_knn   \n",
    "\n",
    "def create_busca(Card_Type: str, Power: int, Toughness: int, CMC: int, Rarity: str, Loyalty: int):\n",
    "    if(Card_Type == \"Planeswalker\"):\n",
    "        busca = np.array([CMC,Rarity,Loyalty,])\n",
    "    elif(Card_Type == \"Creature\" or Card_Type == \"Artifact Creature\"):\n",
    "        busca = np.array([CMC,Power,Toughness,Rarity])\n",
    "    elif(Card_Type == \"Sorcery\" or Card_Type == \"Instant\" or Card_Type == \"Enchantment\"):\n",
    "        busca = np.array([CMC,Rarity])\n",
    "    elif(Card_Type == \"Land\"):\n",
    "        busca = np.array([Rarity])\n",
    "    elif(Card_Type == \"Artifact\"):\n",
    "        busca = np.array([CMC,Rarity])\n",
    "    else:\n",
    "        print(\"Tipo de carta não suportado\")\n",
    "        return None\n",
    "    return busca\n",
    "\n",
    "def run(Card_Type: str, Texto_a_procurar: str, Power: int, Toughness: int, CMC: int, Rarity: str, Loyalty: int):\n",
    "    data1 = pd.read_csv(r'C:\\Users\\drodm\\OneDrive\\Documentos\\GitHub\\Mystic-Speculation-Clusterization-and-Semantic-search-for-Price-aproximation-on-Magic-Cards\\updated_merged_cleaned_with_expansions.csv')\n",
    "    data2 = pd.read_csv(r'C:\\Users\\drodm\\OneDrive\\Documentos\\GitHub\\Mystic-Speculation-Clusterization-and-Semantic-search-for-Price-aproximation-on-Magic-Cards\\expanded_expansions_with_cards.csv')        \n",
    "    # Initialize DataPreprocessing and preprocess data\n",
    "    data_preprocessor = DataPreprocessing()\n",
    "    data = data_preprocessor.merging_data(data1, data2)\n",
    "    Card_Type = Card_Type\n",
    "    busca = create_busca(Card_Type, Power, Toughness, CMC, Rarity, Loyalty)\n",
    "    \n",
    "    df = data_preprocessor.preprocess(data, Card_Type)\n",
    "    # Initialize CardAnalyzer\n",
    "    analyzer = CardAnalyzer(df)\n",
    "    analyzer.clean_data(Card_Type)\n",
    "    Texto_a_procurar = Texto_a_procurar\n",
    "    \n",
    "    scores = analyzer.compute_BM25_similarity(Texto_a_procurar)\n",
    "    df, clustering_model = analyzer.perform_clustering()\n",
    "    if Card_Type == \"Planeswalker\":\n",
    "        # Train the pipeline\n",
    "        analyzer.train_pipe(df[['Total Mana Cost', 'Rarity Category','predicted_cluster','loyalty']], df[\"BM25 Score\"])\n",
    "    elif Card_Type == \"Creature\" or Card_Type == \"Artifact Creature\":\n",
    "        # Train the pipeline\n",
    "        analyzer.train_pipe(df[['Total Mana Cost', 'Power', 'Toughness', 'Rarity Category','predicted_cluster']], df[\"BM25 Score\"])\n",
    "    elif Card_Type == \"Sorcery\" or Card_Type == \"Instant\" or Card_Type == \"Enchantment\":\n",
    "        # Train the pipeline\n",
    "        analyzer.train_pipe(df[['Total Mana Cost', 'Rarity Category','predicted_cluster']], df[\"BM25 Score\"])\n",
    "    elif Card_Type == \"Land\":\n",
    "        # Train the pipeline\n",
    "        analyzer.train_pipe(df[['Rarity Category','predicted_cluster']], df[\"BM25 Score\"])\n",
    "    elif Card_Type == \"Artifact\":\n",
    "        # Train the pipeline\n",
    "        analyzer.train_pipe(df[['Total Mana Cost', 'Rarity Category','predicted_cluster']], df[\"BM25 Score\"])\n",
    "    # Predict and filter\n",
    "    else:\n",
    "        print(\"Tipo de carta não suportado\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "    filtered_predict = analyzer.predict_and_filter(clustering_model,busca)\n",
    "    features, target = analyzer.scale_data(filtered_predict[columns_by_type[Card_Type]].dropna(), filtered_predict[\"Price1\"])\n",
    "    try:\n",
    "        X_train_Minimum , X_test_Minimum, y_train_Minimum, y_test_Minimum = train_test_split(features, target, test_size=0.1, random_state=42)\n",
    "    except:\n",
    "        print('Poucas amostras para treino')\n",
    "        return None\n",
    "    \n",
    "    features, target = analyzer.scale_data(filtered_predict[columns_by_type[Card_Type]].dropna(), filtered_predict[\"Price2\"])\n",
    "    X_train_Medium  , X_test_Medium, y_train_Medium, y_test_Medium = train_test_split(features, target, test_size=0.1, random_state=42)\n",
    "    features, target = analyzer.scale_data(filtered_predict[columns_by_type[Card_Type]].dropna(), filtered_predict[\"Price3\"])\n",
    "    X_train_Maximum, X_test_Maximum, y_train_Maximum, y_test_Maximum = train_test_split(features, target, test_size=0.1, random_state=42)\n",
    "    # Continue with visualization and analysis\n",
    "\n",
    "    analyzer.visualize_3d(filtered_predict, Card_Type)\n",
    "    analyzer.bayesian_analysis(filtered_predict)\n",
    "    analyzer.train_random_forest(X_train_Minimum, y_train_Minimum)\n",
    "    analyzer.train_knn(X_train_Minimum, y_train_Minimum)\n",
    "    mse_rfr, mse_knn, no_knn = analyzer.evaluate_model(X_test_Minimum, y_test_Minimum)\n",
    "\n",
    "    print(f\"Mean Absolute Error (Random Forest): {mse_rfr}, Meann Absolute Error (KNN): {mse_knn}, Menor Preço\")\n",
    "    test_predict_rfr, test_predict_knn = analyzer.predict_value(busca=np.append(busca,np.array([scores.max()+1])), no_knn=no_knn)\n",
    "    print('Preço Mínimo: ',test_predict_rfr.item(), 'Preço Mínimo: ',test_predict_knn.item())\n",
    "\n",
    "    analyzer.train_random_forest(X_train_Medium, y_train_Medium)\n",
    "    analyzer.train_knn(X_train_Medium, y_train_Medium)\n",
    "    mse_rfr, mse_knn, no_knn = analyzer.evaluate_model(X_test_Medium, y_test_Medium)\n",
    "\n",
    "    print(f\"Mean Absolute Error (Random Forest): {mse_rfr}, Meann Absolute Error (KNN): {mse_knn}, Preço Médio\")\n",
    "    test_predict_rfr, test_predict_knn = analyzer.predict_value(busca=np.append(busca,np.array([scores.max()+1])), no_knn=no_knn)\n",
    "    print('Preço Médio: ',test_predict_rfr.item(), 'Preço Médio: ',test_predict_knn.item())\n",
    "\n",
    "    analyzer.train_random_forest(X_train_Maximum, y_train_Maximum)\n",
    "    analyzer.train_knn(X_train_Maximum, y_train_Maximum)\n",
    "    mse_rfr, mse_knn, no_knn = analyzer.evaluate_model(X_test_Maximum, y_test_Maximum)\n",
    "\n",
    "    print(f\"Mean Absolute Error (Random Forest): {mse_rfr}, Meann Absolute Error (KNN): {mse_knn}, Preço Máximo\")\n",
    "    test_predict_rfr, test_predict_knn = analyzer.predict_value(busca=np.append(busca,np.array([scores.max()+1])), no_knn=no_knn)\n",
    "    print('Preço Máximo: ',test_predict_rfr.item(), 'Preço Maximo: ',test_predict_knn.item())\n",
    "\n",
    "# Function to perform analysis after input\n",
    "# Function to perform analysis after input\n",
    "def run_analysis(card_type, mana_cost, card_text, power, toughness, rarity, loyalty):\n",
    "    # Print for debugging to ensure values are captured\n",
    "    #print(f\"Card Type: {card_type}, Mana Cost: {mana_cost}, Text: {card_text}, Power: {power}, Toughness: {toughness}, Rarity: {rarity}, Loyalty: {loyalty}\")\n",
    "    \n",
    "    run(Card_Type=card_type, Texto_a_procurar=card_text, Power=power, Toughness=toughness, CMC=mana_cost, Rarity=rarity, Loyalty=loyalty)\n",
    "\n",
    "# Main GUI setup\n",
    "def main():\n",
    "    with dpg.window(label=\"Card Analyzer\", width=400, height=400):\n",
    "\n",
    "        # Card Type selector\n",
    "        dpg.add_combo(label=\"Select Card Type\", items=card_types, default_value=\"Creature\", tag=\"card_type_selector_unique\")\n",
    "        \n",
    "        # Mana cost input\n",
    "        mana_cost = dpg.add_input_int(label=\"Mana Cost\", tag=\"mana_cost_input_unique\")\n",
    "\n",
    "        # Card text input\n",
    "        card_text = dpg.add_input_text(label=\"Card Text\", tag=\"card_text_input_unique\")\n",
    "\n",
    "        # Power and Toughness (visible only if Creature or Artifact Creature)\n",
    "        with dpg.group(tag=\"creature_inputs_unique\", show=True):\n",
    "            power = dpg.add_input_int(label=\"Power\", tag=\"power_input_unique\")\n",
    "            toughness = dpg.add_input_int(label=\"Toughness\", tag=\"toughness_input_unique\")\n",
    "\n",
    "        # Loyalty (visible only if Planeswalker)\n",
    "        loyalty = dpg.add_input_int(label=\"Loyalty\", tag=\"loyalty_input_unique\", show=False)\n",
    "\n",
    "        # Rarity input\n",
    "        rarity = dpg.add_combo(label=\"Rarity\", items=list(rarity_mapping.keys()), tag=\"rarity_input_unique\")\n",
    "        \n",
    "        # Show/Hide inputs based on card type selection\n",
    "        def card_type_change_callback(sender, app_data):\n",
    "            card_type = dpg.get_value(\"card_type_selector_unique\")\n",
    "            if card_type in [\"Creature\", \"Artifact Creature\"]:\n",
    "                dpg.configure_item(\"creature_inputs_unique\", show=True)\n",
    "                dpg.configure_item(\"loyalty_input_unique\", show=False)\n",
    "            elif card_type == \"Planeswalker\":\n",
    "                dpg.configure_item(\"creature_inputs_unique\", show=False)\n",
    "                dpg.configure_item(\"loyalty_input_unique\", show=True)\n",
    "            elif card_type == \"Land\":\n",
    "                dpg.configure_item(\"creature_inputs_unique\", show=False)\n",
    "                dpg.configure_item(\"loyalty_input_unique\", show=False)\n",
    "                dpg.configure_item(\"mana_cost_input_unique\", show=False)\n",
    "            else:\n",
    "                dpg.configure_item(\"creature_inputs_unique\", show=False)\n",
    "                dpg.configure_item(\"loyalty_input_unique\", show=False)\n",
    "                dpg.configure_item(\"mana_cost_input_unique\", show=True)\n",
    "            \n",
    "\n",
    "        # Link card type change event\n",
    "        dpg.set_item_callback(\"card_type_selector_unique\", card_type_change_callback)\n",
    "\n",
    "        # Button to run the analysis\n",
    "        def on_button_click():\n",
    "            # Forcefully retrieve values from the input fields\n",
    "            card_type = dpg.get_value(\"card_type_selector_unique\")\n",
    "            try:\n",
    "                mana_cost = dpg.get_value(\"mana_cost_input_unique\")\n",
    "            except:\n",
    "                mana_cost = 0\n",
    "            try:\n",
    "                card_text = dpg.get_value(\"card_text_input_unique\")\n",
    "            except:\n",
    "                card_text = \"\"\n",
    "            try:\n",
    "                power = dpg.get_value(\"power_input_unique\")\n",
    "            except:\n",
    "                power = 0\n",
    "            try:\n",
    "                toughness = dpg.get_value(\"toughness_input_unique\")\n",
    "            except:\n",
    "                toughness = 0\n",
    "            try:\n",
    "                rarity = dpg.get_value(\"rarity_input_unique\")\n",
    "                numeric_rarity = rarity_mapping.get(rarity.lower(), -1)  # Retorna -1 se a raridade não for encontrada\n",
    "            except:\n",
    "                numeric_rarity = -1\n",
    "            if numeric_rarity == -1:\n",
    "                dpg.set_value(\"output_text\", f\"Raridade inválida: '{rarity}'. Por favor, selecione uma raridade válida.\")\n",
    "                return  \n",
    "            try:\n",
    "                loyalty = dpg.get_value(\"loyalty_input_unique\")\n",
    "            except:\n",
    "                loyalty = 0\n",
    "\n",
    "        \n",
    "            # Force pass values to run_analysis\n",
    "            run_analysis(card_type, mana_cost, card_text, power, toughness, numeric_rarity, loyalty)\n",
    "        \n",
    "        dpg.add_button(label=\"Run Analysis\", callback=on_button_click)\n",
    "\n",
    "# Initialize DearPyGui\n",
    "dpg.create_context()\n",
    "main()\n",
    "dpg.create_viewport(title='Card Analysis Tool', width=600, height=600)\n",
    "dpg.setup_dearpygui()\n",
    "dpg.show_viewport()\n",
    "dpg.start_dearpygui()\n",
    "dpg.destroy_context()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
